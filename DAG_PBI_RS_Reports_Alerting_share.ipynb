{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.postgres_operator import PostgresOperator\n",
    "from airflow.hooks.postgres_hook import PostgresHook\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from requests_ntlm import HttpNtlmAuth\n",
    "import smtplib\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore')\n",
    "import keyring\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from itertools import product\n",
    "import base64\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _request_data(**context):\n",
    "    ###Авторизация\n",
    "    auth = HttpNtlmAuth(\"Login\", \"password\")\n",
    "\n",
    "\n",
    "    ###Тянем информацию по отчетам\n",
    "    def folder_report_info(folder_id):\n",
    "        url = f'http://server//reports/api/v2.0/Folders({folder_id})/CatalogItems'\n",
    "        response = requests.get(url, auth=auth, verify=False)\n",
    "        resp_json = response.json()\n",
    "        df_folder = pd.DataFrame(resp_json['value'])\n",
    "        df_folder['Folder'] = (df_folder[\"Path\"]\n",
    "                                         .str.split('/', 3).str[2])\n",
    "        return df_folder\n",
    "\n",
    "\n",
    "    ###Собираем фреймы\n",
    "    df_1 = folder_report_info('id') #Id папки PBI RS\n",
    "    df_2 = folder_report_info('id') #Id папки PBI RS\n",
    "    df_3 = folder_report_info('id') #Id папки PBI RS\n",
    "    df_info_ = [df_1,df_2,df_3] #Объединение в единый датафрейм\n",
    "    df_info_ = pd.concat(df_info_) #Объединение в единый датафрейм\n",
    "\n",
    "\n",
    "    ###Собираем ссылки на отчеты для статусов обновления\n",
    "    http_1 = 'http://server//reports/api/v2.0/PowerBIReports('\n",
    "    http_2 = ')/CacheRefreshPlans'\n",
    "    url = [http_1 + x + http_2 for x in df_info_['Id']] #из предыдущей таблицы с основной информацией об отчетах.\n",
    "\n",
    "\n",
    "    ###Собираем статусы обновления по отчетам\n",
    "    df_info_refresh = [] #объявляем пустой список, в который будем складывать записи по api\n",
    "\n",
    "    #Собираем данные для фрейма\n",
    "    for i in range(len(url)): #цикл по ранее полученным ссылкам на отчеты\n",
    "        response = requests.get(str(url[i]), auth=auth, verify=False) #подключение по api\n",
    "        resp_json = response.json() #складываем в json\n",
    "        df_refresh = pd.DataFrame(resp_json['value']) #складываем в фрейм\n",
    "        for j in range(len(df_refresh)): ##для чтения всех записей фреймов\n",
    "            df_info_refresh.append(df_refresh) #добавляем очередную запись в итогоый список\n",
    "    df_info_refresh = pd.concat(df_info_refresh) #склеииваем записи в единый фрейм\n",
    "\n",
    "\n",
    "def _parse_data(**context):\n",
    "    #Обработка фрейма\n",
    "    df_info_refresh = ( \n",
    "    df_info_refresh[['Id', 'Owner', 'Description', \n",
    "                             'CatalogItemPath', 'EventType',\n",
    "                             'ScheduleDescription', 'LastRunTime', \n",
    "                             'LastStatus', 'ModifiedBy','ModifiedDate']]) #объявляем все строки, которые нужны для выгрузки\n",
    "\n",
    "    ###Все статусы обновлений, в т.ч. успешные\n",
    "    df_info_refresh = df_info_refresh.drop_duplicates(keep='last') #удаляем дубликаты (не последние записи)\n",
    "    df_info_refresh[\"ReportName\"] = (df_info_refresh[\"CatalogItemPath\"]\n",
    "                                         .str.split('/', -1).str[-1]) #создаем столбец с названием отчета\n",
    "\n",
    "\n",
    "\n",
    "    ###Что будем отправлять\n",
    "    df_failed_refresh = (df_info_refresh[['Owner','ReportName','CatalogItemPath',\n",
    "                                              'Description','LastRunTime','LastStatus']]\n",
    "                     [df_info_refresh['LastStatus']!='Completed Data Refresh'])\n",
    "\n",
    "\n",
    "def _send_data(**context):\n",
    "    ###Объявление кредов\n",
    "    recipients = ['mail1.ru','mail2.ru'] #Список получателй\n",
    "    emaillist = [elem.strip().split(',') for elem in recipients]\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"Daily Failed Refresh PBI Reporting\" #Тема письма\n",
    "    FROMADDR = \"you@gmail.com\" #С какого почтового адреса будет отправка\n",
    "    LOGIN    = FROMADDR #Логин/Отправитель\n",
    "    PASSWORD = \"yourcode\" #полученный код\n",
    "\n",
    "\n",
    "    ###Заготовка письма\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(df_failed_refresh.to_html()) #Формирование фрейма для отображения в письме\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "\n",
    "    ###Отправка письма\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587) #Отправка письма\n",
    "    server.set_debuglevel(1)\n",
    "    server.set_debuglevel(1)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(LOGIN, PASSWORD)\n",
    "    server.sendmail(FROMADDR, emaillist , msg.as_string())\n",
    "    server.quit() #Закрытие подключения\n",
    "\n",
    "\n",
    "\n",
    "args = {'Your Name': 'Topic'}\n",
    "\n",
    "dag = DAG(\n",
    "    dag_id=\"temp\",\n",
    "    default_args=args,\n",
    "    description='DAG_PBI_Alerting',\n",
    "    start_date=datetime(2023, 1, 1),\n",
    "    schedule_interval='0 9,13,15,18 * * *',\n",
    "    catchup=False,\n",
    ")\n",
    "\n",
    "\n",
    "start = DummyOperator(task_id=\"start\", dag=dag)\n",
    "\n",
    "request_data = PythonOperator(\n",
    "    task_id='request_data', python_callable=_request_data, provide_context=True, dag=dag)\n",
    "parse_data = PythonOperator(\n",
    "    task_id='parse_data', python_callable=_parse_data, provide_context=True, dag=dag)\n",
    "send_data = PythonOperator(\n",
    "    task_id='parse_data', python_callable=_send_data, provide_context=True, dag=dag)\n",
    "\n",
    "\n",
    "\n",
    "start >> request_data >> parse_data >> send_data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
